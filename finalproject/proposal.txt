Overview: Inspired by assignment three, Jamie and I propose to learn and implement a super-resolution model. More specifically, we seek to build the model in Tinygrad, a new machine learning framework whose core codebase remains under 1000 lines of code. We also seek to apply the super-resolution model to satellite imagery for real-world application.

Architecture: Our goal architecture is a model which incorporates learnable upsampling and transformer encoder blocks together to augment a low-resolution image to four-times the original size. Our goal architecture can be thought of as a combination of the two papers “Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network” and “Transformer for Single Image Super-Resolution”. We plan to start by implementing the simplest components initially, training to verify correctness, while gradually increasing architecture complexity. Our planned order of implementation is interpolation, single-kernel, SRCNN, ESPCNN, and finally an encoder only transformer.

Novelty: Our project has multiple areas of novelty. First, we plan to double the low-resolution to high-resolution image ration of SRCNN from 2x to 4x resolution. Furthermore, due to the Tinygrad machine learning framework’s extremely recent release, many models, layers, and functions are not supported. As a result, we will have to write these functions ourselves without the aid of high-level libraries. For example, image-interpolation and sub-pixel convolutions. With Tinygrad being open source, our implementations can be submitted via pull-request to the Tinygrad GitHub repository. Lastly, our model is the first to our knowledge to apply pixel-shuffle and transformer blocks to the task of satellite imagery. 

Dataset: Due to the complexity of satellite imagery, our initial dataset for testing will be much simpler. We obtained 100 images from Kaggle of size 96x96 LR and 384x384 HR. Once our model is performing well on this dataset, we plan to move to the WorldStrat geospatial imagery dataset.

Concerns: One concern regarding our proposed final project is the amount of time it would take to train the model. This is because satellite imagery is often high resolution and contains a large amount of information, which means that it would require a significant amount of time and computing power to train the model on this data. Additionally, unlike classification or regression tasks, we are expanding the input information to higher dimensions, rather than condensing into feature vectors for downstream layers. This is a difficult task and poses challenges considering the short time span of the project.

Conclusion: Overall, we are excited to learn more about super resolution by implementing our own models. Regardless of outcome, we stand to gain a low-level understanding of many famous super-resolution papers, while simultaneously applying our end-model to a real-world application. 

