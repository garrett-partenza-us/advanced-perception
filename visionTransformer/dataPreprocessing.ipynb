{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aea2b750-2fd0-448b-b37c-5801b0a4711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sun.jiam/worldstrat\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6a18d3-ae02-4b78-95bb-9087ff67235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../scratch/sun.jiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c083737-47e3-4fe9-80e3-f5cd34990c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sun.jiam/worldstrat\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/worldstrat/worldstrat\n",
    "%cd worldstrat\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8190342-cc0b-4b6d-aa55-3c31ce1a071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ipywidgets import interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from src.datasets import load_dataset_JIF, SatelliteDataset, DictDataset, make_transforms_JIF\n",
    "from src.datasources import S2_ALL_12BANDS\n",
    "from src.plot import showtensor\n",
    "from multiprocessing import Manager\n",
    "from src.datasources import *\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "from src.plot import showtensor\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "transforms = make_transforms_JIF(lr_bands_to_use='true_color', radiometry_depth=12)\n",
    "multiprocessing_manager = Manager()\n",
    "\n",
    "dataset_root = '../../../scratch/sun.jiam/dataset/'\n",
    "hr_dataset_folder = 'hr_dataset/12bit/'\n",
    "lr_dataset_folder = 'lr_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af1fb869-5a5f-42a1-8ccf-492394546fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all LR bands.\n",
      "Shuffling the dataset splits using 42\n",
      "Train set size: 3143\n",
      "Val set size: 392\n",
      "Test set size: 392\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Manager\n",
    "from src.datasets import load_dataset_JIF\n",
    "import pandas as pd\n",
    "\n",
    "multiprocessing_manager = Manager()\n",
    "list_of_aois = list(\n",
    "    pd.read_csv(\"pretrained_model/stratified_train_val_test_split.csv\", index_col=1).index\n",
    ")\n",
    "kws = dict(\n",
    "    input_size=(400, 400),\n",
    "    output_size=(1024, 1024),\n",
    "    normalize_lr=True,\n",
    "    root=\"../../../scratch/sun.jiam/dataset/\",\n",
    "    radiometry_depth=12,\n",
    "    lr_bands_to_read=\"true_color\",\n",
    ")\n",
    "\n",
    "dataloaders = load_dataset_JIF(**kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec240778-6d4c-405b-bed5-c8a7814fea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataloaders[\"train\"].dataset\n",
    "validation_dataset = dataloaders[\"val\"].dataset\n",
    "test_dataset = dataloaders[\"test\"].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e9569d-864e-47dd-93e0-e2fb583cfdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.5.0\n"
     ]
    }
   ],
   "source": [
    "# ! pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79d9d7eb-7088-4a44-8dfa-f9b4dbe89686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12, 400, 400])\n",
      "torch.Size([8, 1, 400, 400])\n",
      "torch.Size([1, 3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"lr\"].shape)\n",
    "print(train_dataset[0][\"lrc\"].shape)\n",
    "print(train_dataset[0][\"hr\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30b1998a-acf8-4ad9-a125-66ac747ae723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv2d only takes 3d inputs or 4d where the first element is the batch\n",
    "#We can keep the 12 channels, it is very slow to get only RGB. \n",
    "x = train_dataset[0][\"lr\"].reshape(256*8, 12, 25, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d9f4a9d-522c-4dc5-bf3a-c2faf5e5e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini test for 5d input, which didn't work. \n",
    "#We need to convert the 5d input to 3d. \n",
    "# 5d: 256, 8, 12, 25, 25\n",
    "# 3d: 12, 25, 25\n",
    "# The shape of the torch: (256 * 8, 12, 25, 25)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(12, 32, 5, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25d66d4d-884d-4589-bab7-128890ab4ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 21, 21])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conv2d only takes 3d inputs or 4d where the first element is the batch\n",
    "c= ConvNet()\n",
    "x = c(x[0])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc808860-957d-41b9-92bc-6d76c182c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still designing\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(12, 32, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 128, 3, 3)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 11, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.linear(6144, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d63720-000b-47d0-ac92-f62693f7689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, last):\n",
    "        super().__init__()\n",
    "        if not last:\n",
    "            last=dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, last),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.depth = depth\n",
    "        for d in range(depth):\n",
    "            if d == depth-1:\n",
    "                last=out_dim\n",
    "            else: \n",
    "                last=None\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head),\n",
    "                FeedForward(dim, mlp_dim, last)\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for d in range(self.depth):\n",
    "            attn, ff = self.layers[d]\n",
    "            x = attn(x) + x\n",
    "            x = ff(x)\n",
    "            if d!=self.depth-1:\n",
    "                x+=x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb7f92-8f0a-4290-a3d8-11f1f2e1a917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
